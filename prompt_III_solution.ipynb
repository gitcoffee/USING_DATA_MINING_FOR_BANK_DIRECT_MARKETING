{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta:\n",
    "\n",
    "En la sección \"Materials and Methods\" del artículo asociado con este dataset, se explica que los datos provienen de dos campañas de marketing:\n",
    "\n",
    "Una campaña anterior representada por datos adicionales relacionados con contactos previos (pdays, previous, y poutcome).\n",
    "Una campaña actual, de la cual se registraron las llamadas telefónicas y su resultado directo.\n",
    "Por lo tanto, el dataset refleja tanto los datos de una campaña pasada como los datos de una campaña actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Escritorio/progress_/certicate_berkeley_course_v-17sep/17_module_seventeen/module_17_starter (1)/data/bank-additional-full.csv', sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   age        job  marital    education  default housing loan    contact  \\\n",
       " 0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       " 1   57   services  married  high.school  unknown      no   no  telephone   \n",
       " 2   37   services  married  high.school       no     yes   no  telephone   \n",
       " 3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       " 4   56   services  married  high.school       no      no  yes  telephone   \n",
       " \n",
       "   month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       " 0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       " 1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       " 2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       " 3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       " 4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       " \n",
       "    cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       " 0          93.994          -36.4      4.857       5191.0  no  \n",
       " 1          93.994          -36.4      4.857       5191.0  no  \n",
       " 2          93.994          -36.4      4.857       5191.0  no  \n",
       " 3          93.994          -36.4      4.857       5191.0  no  \n",
       " 4          93.994          -36.4      4.857       5191.0  no  \n",
       " \n",
       " [5 rows x 21 columns],\n",
       " None,\n",
       "                 age     job  marital          education default housing  \\\n",
       " count   41188.00000   41188    41188              41188   41188   41188   \n",
       " unique          NaN      12        4                  8       3       3   \n",
       " top             NaN  admin.  married  university.degree      no     yes   \n",
       " freq            NaN   10422    24928              12168   32588   21576   \n",
       " mean       40.02406     NaN      NaN                NaN     NaN     NaN   \n",
       " std        10.42125     NaN      NaN                NaN     NaN     NaN   \n",
       " min        17.00000     NaN      NaN                NaN     NaN     NaN   \n",
       " 25%        32.00000     NaN      NaN                NaN     NaN     NaN   \n",
       " 50%        38.00000     NaN      NaN                NaN     NaN     NaN   \n",
       " 75%        47.00000     NaN      NaN                NaN     NaN     NaN   \n",
       " max        98.00000     NaN      NaN                NaN     NaN     NaN   \n",
       " \n",
       "          loan   contact  month day_of_week  ...      campaign         pdays  \\\n",
       " count   41188     41188  41188       41188  ...  41188.000000  41188.000000   \n",
       " unique      3         2     10           5  ...           NaN           NaN   \n",
       " top        no  cellular    may         thu  ...           NaN           NaN   \n",
       " freq    33950     26144  13769        8623  ...           NaN           NaN   \n",
       " mean      NaN       NaN    NaN         NaN  ...      2.567593    962.475454   \n",
       " std       NaN       NaN    NaN         NaN  ...      2.770014    186.910907   \n",
       " min       NaN       NaN    NaN         NaN  ...      1.000000      0.000000   \n",
       " 25%       NaN       NaN    NaN         NaN  ...      1.000000    999.000000   \n",
       " 50%       NaN       NaN    NaN         NaN  ...      2.000000    999.000000   \n",
       " 75%       NaN       NaN    NaN         NaN  ...      3.000000    999.000000   \n",
       " max       NaN       NaN    NaN         NaN  ...     56.000000    999.000000   \n",
       " \n",
       "             previous     poutcome  emp.var.rate  cons.price.idx  \\\n",
       " count   41188.000000        41188  41188.000000    41188.000000   \n",
       " unique           NaN            3           NaN             NaN   \n",
       " top              NaN  nonexistent           NaN             NaN   \n",
       " freq             NaN        35563           NaN             NaN   \n",
       " mean        0.172963          NaN      0.081886       93.575664   \n",
       " std         0.494901          NaN      1.570960        0.578840   \n",
       " min         0.000000          NaN     -3.400000       92.201000   \n",
       " 25%         0.000000          NaN     -1.800000       93.075000   \n",
       " 50%         0.000000          NaN      1.100000       93.749000   \n",
       " 75%         0.000000          NaN      1.400000       93.994000   \n",
       " max         7.000000          NaN      1.400000       94.767000   \n",
       " \n",
       "         cons.conf.idx     euribor3m   nr.employed      y  \n",
       " count    41188.000000  41188.000000  41188.000000  41188  \n",
       " unique            NaN           NaN           NaN      2  \n",
       " top               NaN           NaN           NaN     no  \n",
       " freq              NaN           NaN           NaN  36548  \n",
       " mean       -40.502600      3.621291   5167.035911    NaN  \n",
       " std          4.628198      1.734447     72.251528    NaN  \n",
       " min        -50.800000      0.634000   4963.600000    NaN  \n",
       " 25%        -42.700000      1.344000   5099.100000    NaN  \n",
       " 50%        -41.800000      4.857000   5191.000000    NaN  \n",
       " 75%        -36.400000      4.961000   5228.100000    NaN  \n",
       " max        -26.900000      5.045000   5228.100000    NaN  \n",
       " \n",
       " [11 rows x 21 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando las primeras filas del dataset y sus estadísticas generales\n",
    "data_head = data.head()\n",
    "data_info = data.info()\n",
    "data_description = data.describe(include='all')\n",
    "\n",
    "data_head, data_info, data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se concluye que: El dataset contiene **41,188 registros y 21 columnas**. \n",
    "\n",
    "De la Siguinte forma:\n",
    "\n",
    "1. **Variables categóricas**:\n",
    "   - Hay 11 columnas categóricas, incluyendo `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `day_of_week`, `poutcome`, y el objetivo `y`.\n",
    "   - Por ejemplo: La variable `job` tiene 12 categorías, siendo \"admin.\" la más frecuente.\n",
    "\n",
    "2. **Variables numéricas**:\n",
    "   - Hay 10 columnas numéricas como `age`, `duration`, `campaign`, `pdays`, `previous`, y otras relacionadas con tasas y empleo.\n",
    "   - Por ejemplo: La edad media de los clientes es de 40 años, con un rango de 17 a 98 años.\n",
    "\n",
    "3. **Variable objetivo (`y`)**:\n",
    "   - Es una variable categórica binaria (`yes`/`no`), indicando si un cliente aceptó un depósito a plazo.\n",
    "\n",
    "4. **Posibles áreas de interés**:\n",
    "   - La variable `pdays` tiene un valor predominante de 999, lo cual podría indicar \"no contacto previo\".\n",
    "   - `duration` mide el tiempo de la última llamada en segundos, que podría influir significativamente en el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "---\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cumplir con la tarea, se examina si hay valores faltantes o si las variables necesitan ser convertidas a un tipo de dato diferente basándonos en la descripción proporcionada, el análisis paso a paso:\n",
    "\n",
    "### **1. Limpieza de datos**\n",
    "   - **Valores nulos**: Identificar y manejar valores faltantes.\n",
    "   - **Valores anómalos**: Detectar y tratar outliers si afectan al modelo.\n",
    "   - **Codificación de valores irrelevantes**: Como `999` en `pdays`, que podría tratarse como un indicador especial.\n",
    "\n",
    "### **2. Selección de características**\n",
    "   - Eliminar columnas irrelevantes, redundantes o poco útiles.\n",
    "   - Seleccionar variables significativas según el problema (por ejemplo, excluir identificadores).\n",
    "\n",
    "### **3. Transformación de variables**\n",
    "   - **Codificación de variables categóricas**:\n",
    "     - Usar `One-Hot Encoding` para variables categóricas nominales.\n",
    "     - Usar `Label Encoding` si la categoría tiene un orden lógico.\n",
    "   - **Estandarización o normalización**:\n",
    "     - Escalar variables numéricas (como tasas o duraciones) para mejorar el rendimiento de ciertos modelos (por ejemplo, SVM, KNN).\n",
    "\n",
    "### **4. Manejo del desbalanceo de clases**\n",
    "   - Si la variable objetivo (`y`) está desbalanceada (por ejemplo, más \"no\" que \"yes\"), utilizar técnicas como:\n",
    "     - Re-muestreo (`oversampling`, `undersampling`).\n",
    "     - Asignar pesos a las clases.\n",
    "     - Generar datos sintéticos (como **SMOTE**).\n",
    "\n",
    "En este caso, los pasos específicos son:\n",
    "- Codificar variables categóricas como `job`, `marital`, y `education`.\n",
    "- Escalar variables como `duration`, `age` y `campaign`.\n",
    "- Manejar `999` en `pdays` para distinguir \"sin contacto previo\".\n",
    "- Asegurarnos de que `y` esté balanceada o ajustar el modelo para manejar el desbalanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age               0\n",
       " job               0\n",
       " marital           0\n",
       " education         0\n",
       " default           0\n",
       " housing           0\n",
       " loan              0\n",
       " contact           0\n",
       " month             0\n",
       " day_of_week       0\n",
       " duration          0\n",
       " campaign          0\n",
       " pdays             0\n",
       " previous          0\n",
       " poutcome          0\n",
       " emp.var.rate      0\n",
       " cons.price.idx    0\n",
       " cons.conf.idx     0\n",
       " euribor3m         0\n",
       " nr.employed       0\n",
       " y                 0\n",
       " dtype: int64,\n",
       " pdays\n",
       " 999    39673\n",
       " 3        439\n",
       " 6        412\n",
       " 4        118\n",
       " 9         64\n",
       " Name: count, dtype: int64,\n",
       " {'job': job\n",
       "  admin.           10422\n",
       "  blue-collar       9254\n",
       "  technician        6743\n",
       "  services          3969\n",
       "  management        2924\n",
       "  retired           1720\n",
       "  entrepreneur      1456\n",
       "  self-employed     1421\n",
       "  housemaid         1060\n",
       "  unemployed        1014\n",
       "  student            875\n",
       "  unknown            330\n",
       "  Name: count, dtype: int64,\n",
       "  'marital': marital\n",
       "  married     24928\n",
       "  single      11568\n",
       "  divorced     4612\n",
       "  unknown        80\n",
       "  Name: count, dtype: int64,\n",
       "  'education': education\n",
       "  university.degree      12168\n",
       "  high.school             9515\n",
       "  basic.9y                6045\n",
       "  professional.course     5243\n",
       "  basic.4y                4176\n",
       "  basic.6y                2292\n",
       "  unknown                 1731\n",
       "  illiterate                18\n",
       "  Name: count, dtype: int64,\n",
       "  'default': default\n",
       "  no         32588\n",
       "  unknown     8597\n",
       "  yes            3\n",
       "  Name: count, dtype: int64,\n",
       "  'housing': housing\n",
       "  yes        21576\n",
       "  no         18622\n",
       "  unknown      990\n",
       "  Name: count, dtype: int64,\n",
       "  'loan': loan\n",
       "  no         33950\n",
       "  yes         6248\n",
       "  unknown      990\n",
       "  Name: count, dtype: int64,\n",
       "  'contact': contact\n",
       "  cellular     26144\n",
       "  telephone    15044\n",
       "  Name: count, dtype: int64,\n",
       "  'month': month\n",
       "  may    13769\n",
       "  jul     7174\n",
       "  aug     6178\n",
       "  jun     5318\n",
       "  nov     4101\n",
       "  apr     2632\n",
       "  oct      718\n",
       "  sep      570\n",
       "  mar      546\n",
       "  dec      182\n",
       "  Name: count, dtype: int64,\n",
       "  'day_of_week': day_of_week\n",
       "  thu    8623\n",
       "  mon    8514\n",
       "  wed    8134\n",
       "  tue    8090\n",
       "  fri    7827\n",
       "  Name: count, dtype: int64,\n",
       "  'poutcome': poutcome\n",
       "  nonexistent    35563\n",
       "  failure         4252\n",
       "  success         1373\n",
       "  Name: count, dtype: int64,\n",
       "  'y': y\n",
       "  no     36548\n",
       "  yes     4640\n",
       "  Name: count, dtype: int64})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisar valores nulos\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Inspeccionar la columna `pdays` para identificar valores especiales\n",
    "pdays_unique_values = data['pdays'].value_counts()\n",
    "\n",
    "# Analizar si hay valores irrelevantes o categorías con poca representación\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "categorical_summary = {col: data[col].value_counts() for col in categorical_columns}\n",
    "\n",
    "missing_values, pdays_unique_values.head(), categorical_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí están los resultados iniciales de limpieza:\n",
    "\n",
    "### **Valores nulos**\n",
    "- No hay valores faltantes explícitos en ninguna columna.\n",
    "\n",
    "### **Columna `pdays`**\n",
    "- El valor `999` aparece en **39,673 registros** (96.3% del total), lo que parece indicar que el cliente no fue contactado en campañas anteriores. Este valor necesita un tratamiento especial (como reemplazarlo con una etiqueta categórica o crear una nueva variable binaria).\n",
    "\n",
    "### **Variables categóricas**\n",
    "1. **Columnas con categorías sospechosas**:\n",
    "   - **`default`**: Tiene **3 registros** como \"yes\", lo que podría ser poco significativo.\n",
    "   - **`unknown`**: Aparece en varias columnas (`default`, `housing`, `loan`, `education`, etc.), indicando información faltante implícita.\n",
    "\n",
    "2. **Distribución de la variable objetivo (`y`)**:\n",
    "   - Muy desbalanceada: **36,548** \"no\" y **4,640** \"yes\" (~88% vs 12%).\n",
    "\n",
    "### **Siguientes pasos son**\n",
    "1. **Tratamiento de `pdays`**:\n",
    "   - Convertir `pdays` en dos variables: una binaria indicando contacto previo y otra para el número de días (donde `999` sería \"sin contacto\").\n",
    "2. **Manejo de valores `unknown`**:\n",
    "   - Considerarlos como una categoría separada o tratarlos como valores faltantes según el contexto.\n",
    "3. **Análisis del desbalanceo de clases**:\n",
    "   - Mantenerlo en mente para ajustar los modelos o usar técnicas de balanceo.\n",
    "\n",
    "---\n",
    "\n",
    "1. Tratamiento de pdays\n",
    "Crear una nueva variable binaria was_contacted_before, donde:\n",
    "1 indica contacto previo (cualquier valor distinto de 999).\n",
    "0 indica \"sin contacto\" (valor 999).\n",
    "Eliminar la columna original pdays.\n",
    "2. Manejo de valores unknown\n",
    "En las columnas categóricas, tratar unknown como una categoría separada. Este enfoque evitará pérdida de información y problemas para el modelo más adelante.\n",
    "3. Validación\n",
    "Revisar los resultados después de las transformaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(was_contacted_before\n",
       " 0    39673\n",
       " 1     1515\n",
       " Name: count, dtype: int64,\n",
       " True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 1: Crear la variable binaria para `pdays`\n",
    "data['was_contacted_before'] = (data['pdays'] != 999).astype(int)\n",
    "\n",
    "# Eliminar la columna original `pdays`\n",
    "data_cleaned = data.drop(columns=['pdays'])\n",
    "\n",
    "# Validación 1: Confirmar que la transformación se realizó correctamente\n",
    "contacted_summary = data_cleaned['was_contacted_before'].value_counts()\n",
    "columns_after_pdays = data_cleaned.columns\n",
    "\n",
    "# Confirmar que la transformación es correcta y sin errores\n",
    "contacted_summary, 'pdays' not in columns_after_pdays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 (sin contacto previo): 39,673 registros (96.3%).\n",
    "1 (contactado previamente): 1,515 registros (3.7%).\n",
    "La columna original pdays se eliminó correctamente del dataset.\n",
    "Luego se va a proceder con el tratamiento de los valores unknown en las variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': True,\n",
       " 'marital': True,\n",
       " 'education': True,\n",
       " 'default': True,\n",
       " 'housing': True,\n",
       " 'loan': True,\n",
       " 'contact': True,\n",
       " 'month': True,\n",
       " 'day_of_week': True,\n",
       " 'poutcome': True,\n",
       " 'y': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 2: Manejo de valores `unknown` en columnas categóricas\n",
    "for col in categorical_columns:\n",
    "    if 'unknown' in data_cleaned[col].values:\n",
    "        data_cleaned[col] = data_cleaned[col].replace('unknown', 'Unknown')\n",
    "\n",
    "# Validación 2: Confirmar que todas las ocurrencias de \"unknown\" fueron manejadas correctamente\n",
    "unknown_replacement_check = {\n",
    "    col: 'unknown' not in data_cleaned[col].values for col in categorical_columns\n",
    "}\n",
    "\n",
    "unknown_replacement_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **objetivo empresarial** de este conjunto de datos es **predecir si un cliente se suscribirá a un depósito a plazo fijo** durante una campaña de marketing telefónico realizada por un banco. Esto tiene como propósito **mejorar la eficiencia de la campaña**, reduciendo el número de contactos innecesarios y enfocándose en aquellos clientes que tienen una mayor probabilidad de suscribirse al producto.\n",
    "\n",
    "### Detalles clave del objetivo:\n",
    "- **Producto**: Depósito a plazo fijo.\n",
    "- **Método de marketing**: Campaña de marketing directa, principalmente a través de llamadas telefónicas.\n",
    "- **Meta**: Desarrollar un modelo predictivo que pueda identificar qué clientes tienen más probabilidades de aceptar la oferta y suscribir el depósito a plazo, con el fin de optimizar los recursos del banco (tiempo de los agentes, cantidad de llamadas, etc.).\n",
    "- **Beneficio**: Incrementar la tasa de éxito de la campaña, reduciendo costos y maximizando los beneficios para el banco.\n",
    "\n",
    "Este objetivo se logra al analizar los datos históricos de los clientes, sus características demográficas y el historial de contacto con campañas previas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de completar la limpieza de los datos, el siguiente paso es prepararlos para el modelo de machine learning. Esto incluye realizar las transformaciones necesarias y dividir el conjunto de datos. Aquí está el desglose de lo que sigue:\n",
    "\n",
    "1. Codificación de variables categóricas\n",
    "Convertir las columnas categóricas en variables numéricas. Por ejemplo:\n",
    "Usar One-Hot Encoding para variables sin orden natural (como job, marital, education).\n",
    "Usar Label Encoding si hay un orden lógico.\n",
    "2. Escalamiento de variables numéricas\n",
    "Para modelos que dependen de la escala de los datos (como SVM, KNN), normalizar o estandarizar variables como age, campaign, y duration.\n",
    "3. Dividir el dataset\n",
    "Separar las características independientes (X) y la variable objetivo (y).\n",
    "Dividir el dataset en:\n",
    "Entrenamiento (70%-80%): Para ajustar el modelo.\n",
    "Prueba (20%-30%): Para evaluar el rendimiento.\n",
    "4. Balanceo de clases\n",
    "Si el conjunto está desbalanceado (como en este caso), aplicar estrategias como:\n",
    "Re-muestreo (oversampling, undersampling).\n",
    "Generar datos sintéticos con SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Limpieza de datos\n",
    "# Reemplazar \"unknown\" en variables categóricas por un valor que no interfiera (e.g., \"other\")\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].replace('unknown', 'other')\n",
    "\n",
    "# Convertir la variable objetivo a binaria (1 para \"yes\", 0 para \"no\")\n",
    "data['y'] = data['y'].apply(lambda val: 1 if val == 'yes' else 0)\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = data.drop(columns=['y'])  # Características\n",
    "y = data['y']  # Objetivo\n",
    "\n",
    "# Identificar columnas categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Crear preprocesador para codificación y escalamiento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),  # Escalar variables numéricas\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # Codificar categóricas\n",
    "    ],\n",
    "    remainder='passthrough'  # Mantener las columnas que no se transforman\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train después del balanceo: (51166, 64)\n",
      "Distribución de clases en y_train después del balanceo:\n",
      "y\n",
      "0    25583\n",
      "1    25583\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Forma de X_test: (12357, 64)\n",
      "Distribución de clases en y_test:\n",
      "y\n",
      "0    10965\n",
      "1     1392\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Transformar características y aplicar balanceo en el conjunto de entrenamiento\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Balancear las clases en el conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Transformar el conjunto de prueba (sin balancear)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Revisar las formas de los conjuntos y la distribución de clases después del balanceo\n",
    "print(\"Forma de X_train después del balanceo:\", X_train_balanced.shape)\n",
    "print(\"Distribución de clases en y_train después del balanceo:\")\n",
    "print(y_train_balanced.value_counts())\n",
    "print(\"\\nForma de X_test:\", X_test_transformed.shape)\n",
    "print(\"Distribución de clases en y_test:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que el balanceo de clases se ha realizado correctamente en el conjunto de entrenamiento, ya que ahora  se tiene el mismo número de ejemplos para ambas clases (25583 para la clase 0 y 25583 para la clase 1). Sin embargo, en el conjunto de prueba, las clases siguen estando desbalanceadas, lo cual es común cuando se usan datos reales.\n",
    "\n",
    "Conjunto de entrenamiento (X_train): Se ha balanceado correctamente con SMOTE, por lo que las clases están equilibradas (25583 muestras de cada clase).\n",
    "Conjunto de prueba (X_test): Aunque el conjunto de prueba no se balancea, la distribución sigue mostrando una desproporción en la cantidad de ejemplos de cada clase (10965 para la clase 0 frente a 1392 para la clase 1). Esto refleja el desbalance original de clases en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Para establecer un modelo base en un problema de clasificación, se necesitará evaluar cuál sería el rendimiento de un modelo muy simple que haga predicciones sin tener en cuenta las características del conjunto de datos.\n",
    "\n",
    "**Enfoque para el modelo base:**\n",
    "    - **Modelo base: Predicción mayoritaria (class imbalance):**\n",
    "        - Una forma común de establecer un modelo base es hacer que el modelo siempre prediga la clase más frecuente (en este caso, \"no\", ya que generalmente hay más clientes que no se suscriben al depósito a plazo).\n",
    "    - **Métricas de rendimiento del modelo base:**\n",
    "        - **Precisión:** La proporción de predicciones correctas con respecto al total de predicciones.\n",
    "        - **Recall:** La proporción de clientes suscritos correctamente identificados como \"sí\".\n",
    "        - **F1-score:** Una medida combinada de la precisión y el recall.\n",
    "    - **Proceso:**\n",
    "        - Determinar cuál es la clase mayoritaria (en este caso, probablemente \"no\").\n",
    "        - Evaluar el rendimiento del modelo base que predice siempre esa clase.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación de la Línea Base:\n",
      "Accuracy (precisión): 0.8873512988589464\n",
      "Matriz de confusión:\n",
      "[[10965     0]\n",
      " [ 1392     0]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     10965\n",
      "           1       0.00      0.00      0.00      1392\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.44      0.50      0.47     12357\n",
      "weighted avg       0.79      0.89      0.83     12357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user007/anaconda3/envs/base_clone/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user007/anaconda3/envs/base_clone/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user007/anaconda3/envs/base_clone/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Establecer una predicción de línea base: siempre predecir la clase mayoritaria (en este caso, 0)\n",
    "y_pred_baseline = [0] * len(y_test)\n",
    "\n",
    "# Evaluar el rendimiento de la línea base\n",
    "print(\"Evaluación de la Línea Base:\")\n",
    "print(\"Accuracy (precisión):\", accuracy_score(y_test, y_pred_baseline))\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_baseline))\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la evaluación de la línea base muestra que el modelo trivial (que predice siempre la clase 0) tiene una precisión de 88.7%, pero también revela algunos aspectos a tomar en cuenta:\n",
    "\n",
    "Precisión (Accuracy): La precisión es de 0.89, lo que significa que el modelo acierta en el 89% de las predicciones. Sin embargo, esto no refleja necesariamente un buen desempeño en cuanto a la capacidad de predecir la clase minoritaria (1), ya que siempre predice la clase mayoritaria (0).\n",
    "\n",
    "El modelo predice 10965 veces la clase 0 correctamente.\n",
    "El modelo no predice ninguna vez la clase 1.\n",
    "\n",
    "Para la clase 0, la precisión es de 0.89 y el recall es de 1.00, lo que indica que el modelo siempre acierta cuando predice la clase 0.\n",
    "Para la clase 1, el recall y la precisión son 0.00, ya que nunca predice la clase 1.\n",
    "\n",
    "Los warnings indican que la precisión de la clase 1 no puede ser calculada (división por cero), ya que el modelo nunca predice esa clase. Esto es un comportamiento esperado para un modelo que siempre elige la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo de Regresión Logística:\n",
      "Accuracy (precisión): 0.9115076474872542\n",
      "Matriz de confusión:\n",
      "[[7103  200]\n",
      " [ 529  406]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95      7303\n",
      "         yes       0.67      0.43      0.53       935\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.80      0.70      0.74      8238\n",
      "weighted avg       0.90      0.91      0.90      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Asumiendo que ya has realizado la limpieza y balanceo de datos, tomamos df limpio y balanceado\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y) antes de la codificación\n",
    "X = df.drop('y', axis=1)  # 'y' es la columna de la variable objetivo\n",
    "y = df['y']\n",
    "\n",
    "# Codificar las variables categóricas usando pd.get_dummies\n",
    "df_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (usa el mismo random_state para consistencia)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características (esto es importante para modelos como la regresión logística)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo de Regresión Logística\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Evaluación del modelo de Regresión Logística:\")\n",
    "print(\"Accuracy (precisión):\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de **Regresión Logística** ha dado buenos resultados con una **precisión de 0.91**. Sin embargo, hay algunos aspectos que observar y mejorar:\n",
    "\n",
    "### Resultados clave:\n",
    "- **Precisión**: 0.91, lo que indica que el modelo tiene un rendimiento bastante sólido en general.\n",
    "- **Matriz de Confusión**:\n",
    "  - **Clase 0 (\"no\")**: El modelo ha clasificado bien a los clientes que no se suscriben al depósito (0).\n",
    "  - **Clase 1 (\"sí\")**: El modelo tiene dificultades para predecir correctamente a los clientes que sí se suscriben al depósito (1), ya que la **recall** es de solo 0.43, lo que significa que no detecta correctamente muchos de los casos positivos.\n",
    "- **Desbalanceo de clases**: El modelo está teniendo dificultades para predecir correctamente la clase minoritaria (clientes que se suscriben al depósito). Esto es común en problemas con clases desbalanceadas, y se puede abordar utilizando técnicas como **SMOTE**.\n",
    "- **Recall de la clase \"sí\"**: La **recall** de 0.43 para la clase \"sí\" sugiere que el modelo está siendo conservador al predecir los casos positivos (clientes que se suscriben), y necesita mejorar en este aspecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión del modelo:\n",
    "Accuracy (precisión): 0.9115 (aproximadamente 91.15%)\n",
    "Este valor refleja la proporción de predicciones correctas en comparación con el total de predicciones realizadas. En este caso, el modelo acertó aproximadamente el 91.15% de las veces en las predicciones realizadas en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "---\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user007/anaconda3/envs/base_clone/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression      0.2137          0.9085         0.9098\n",
      "1                  KNN      0.0225          0.9317         0.9014\n",
      "2        Decision Tree      0.1610          1.0000         0.8865\n",
      "3                  SVM      5.8837          0.8985         0.8945\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Definir los modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Preparar el DataFrame para los resultados\n",
    "results = []\n",
    "\n",
    "# Ajustar y evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    # Medir el tiempo de entrenamiento\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Calcular las precisiones\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Almacenar los resultados\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Time': round(train_time, 4),\n",
    "        'Train Accuracy': round(train_accuracy, 4),\n",
    "        'Test Accuracy': round(test_accuracy, 4)\n",
    "    })\n",
    "\n",
    "# Crear el DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados actuales:\n",
    "\n",
    "La regresión logística tiene un Test Accuracy de 0.9098, que es bastante buena, pero mejorar su convergencia con los métodos mencionados puede hacerlo aún más robusto.\n",
    "\n",
    "El KNN tiene un rendimiento sólido con 0.9014 en el conjunto de prueba, pero también podría beneficiarse del escalado.\n",
    "\n",
    "El Decision Tree tiene un accuracy perfecto en el entrenamiento (1.0000), pero su precisión en el conjunto de prueba está alrededor de 0.8865, lo que podría indicar overfitting.\n",
    "\n",
    "El SVM tiene un accuracy de prueba de 0.8945, pero su tiempo de entrenamiento es bastante alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploración y Ingeniería de Características:\n",
    "La ingeniería de características es clave para mejorar el rendimiento de los modelos. Aquí algunas recomendaciones para mejorar las características y su impacto en los modelos:\n",
    "\n",
    "¿Se debería mantener la característica 'gender'?\n",
    "El género (gender) podría ser relevante dependiendo de la relación con el comportamiento de suscripciones a depósitos a plazo fijo. Para decidir si mantenerlo o no:\n",
    "\n",
    "Mantenerlo: Si existe una tendencia a que ciertos géneros tengan más probabilidad de suscribirse, puede ser útil.\n",
    "\n",
    "Eliminarlo: Si el género no muestra una relación clara con la variable objetivo o puede introducir sesgos, se podría considerar eliminarlo.\n",
    "\n",
    "Transformaciones y nuevas características:\n",
    "\n",
    "Interacciones entre características: Crear nuevas características que representen interacciones entre variables, por ejemplo, combinar job con age para ver si el tipo de trabajo tiene más impacto dependiendo de la edad del cliente.\n",
    "\n",
    "Características de tiempo: Si los datos tienen un componente temporal (por ejemplo, la campaña de marketing dura un tiempo), se podrí agregar características que capturen el momento en que el cliente fue contactado.\n",
    "\n",
    "Normalización o escalado: Ya que algunos modelos como el KNN y la regresión logística son sensibles a las escalas, se puede asegurar normalizar las características correctamente (usando, por ejemplo, StandardScaler).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Búsqueda de Hiperparámetros y Ajuste de Modelos (Grid Search):\n",
    "   \n",
    "Cada modelo tiene hiperparámetros que pueden ajustarse para mejorar el rendimiento. Algunos ejemplos son:\n",
    "\n",
    "KNN: El número de vecinos (n_neighbors), el tipo de distancia (por ejemplo, manhattan vs. euclidean), y el peso de los vecinos (uniform o distance).\n",
    "\n",
    "Árbol de Decisión: La profundidad máxima (max_depth), el mínimo número de muestras para dividir un nodo (min_samples_split), y el mínimo número de muestras en una hoja (min_samples_leaf).\n",
    "\n",
    "SVM: El tipo de kernel (linear, rbf), la regularización (C), y el parámetro gamma.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ajuste de la Métrica de Evaluación:\n",
    "En un contexto de desbalance de clases, la precisión (accuracy) puede no ser suficiente. Se puede considerar otras métricas como:\n",
    "\n",
    "Precisión, Recall y F1-Score: Más útiles cuando tienes clases desbalanceadas.\n",
    "Curvas ROC y AUC: Para evaluar la capacidad del modelo para discriminar entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
